{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40536,
     "status": "ok",
     "timestamp": 1621690944256,
     "user": {
      "displayName": "Laith Siryani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjJxuGtcuWIIgSgmTcVx0kmTMh6B9oVBIv-X3h1=s64",
      "userId": "01519582617178036595"
     },
     "user_tz": -120
    },
    "id": "YhO2J3K67tH9",
    "outputId": "16711deb-48a2-4f62-accc-616f19141e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./metalearning')\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  inColab = True\n",
    "except:\n",
    "  pass\n",
    "os.environ[\"DatabaseDir\"]=\"/content/drive/My Drive/Thesis/Shared/Datasets/\"\n",
    "os.environ[\"DATASRC\"]=\"/content/datasets\"\n",
    "os.environ[\"SPLITS\"]=\"/content/datasets/Splits\"\n",
    "os.environ[\"RECORDS\"]=\"/content/datasets/Records\"\n",
    "if not os.path.isdir(os.environ[\"DATASRC\"]):\n",
    "  os.mkdir(os.environ[\"DATASRC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6p3SWwM-fS_y"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.environ[\"DATASRC\"],\"Records\")):\n",
    "  !cp /content/drive/My\\ Drive/Thesis/Shared/Datasets/records.zip \"$DATASRC\"\n",
    "  !cp /content/drive/My\\ Drive/Thesis/Shared/Datasets/splits.zip \"$DATASRC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jv3BHZQQfS_z"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.environ[\"DATASRC\"],\"Records\")):\n",
    "  os.chdir(os.environ[\"DATASRC\"])\n",
    "  !unzip -q splits.zip  -d ./\n",
    "  !unzip -q records.zip  -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "E1MXY8XQbaTL"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BcwF2RGnp1Zy"
   },
   "outputs": [],
   "source": [
    "sys.path.append('/content/metalearning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CGZhQN6s7qww"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from metalearning_tasks.fixed_shot_classification_v2 import DatasetGenerator\n",
    "from models.model_builder import create_one_hot_model_convolutional, create_cnn, create_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RrJ9Knrcsg4e"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_error = tf.keras.metrics.Mean('train_error', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tMKZVZGtZDDW"
   },
   "outputs": [],
   "source": [
    "exp_no = 18\n",
    "batch_size = _batch_size = 32\n",
    "nb_classes = _nb_classes = 5\n",
    "nb_samples_per_class = _nb_samples_per_class = 10\n",
    "_input_height = _input_width = 112\n",
    "colorspace = 'RGB'\n",
    "channels = {'RGB':3, 'L':1}\n",
    "_iterations = 100000\n",
    "\n",
    "img_size = (_input_height, _input_width)\n",
    "img_shape = [_input_height, _input_width, channels[colorspace]]\n",
    "\n",
    "input_size = _input_height * _input_width * channels[colorspace]\n",
    "cell = 'DNC'\n",
    "nb_reads = _nb_reads = 1\n",
    "controller_size = _controller_size = 100\n",
    "memory_size = _memory_locations = 128\n",
    "memory_dim = ar_memory_word_size = 20\n",
    "summary_interval = 100\n",
    "checkpt_write_interval = 1000\n",
    "dataset = 'vgg_flower'\n",
    "splits=[70,15,15]\n",
    "\n",
    "learning_rate = _learning_rate = 1e-4\n",
    "start=0\n",
    "save_dir='/content/drive/MyDrive/Documents/MSC/Courses/Thesis/Experiments_New/Convolutional4L'\n",
    "_start_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bhV-onqBcTmB"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
       "            url.searchParams.set('tensorboardColab', 'true');\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir '{save_dir}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "f4vjtGinsiZs"
   },
   "outputs": [],
   "source": [
    "def metric_accuracy(_nb_classes,_nb_samples_per_class,labels, outputs):\n",
    "    seq_length = _nb_classes * _nb_samples_per_class\n",
    "    outputs = np.argmax(outputs, axis=-1)\n",
    "    correct = [0] * seq_length\n",
    "    total = [0] * seq_length\n",
    "    for i in range(np.shape(labels)[0]):\n",
    "        label = labels[i]\n",
    "        output = outputs[i]\n",
    "        class_count = {}\n",
    "        for j in range(seq_length):\n",
    "            class_count[label[j]] = class_count.get(label[j], 0) + 1\n",
    "            total[class_count[label[j]]] += 1\n",
    "            if label[j] == output[j]:\n",
    "                correct[class_count[label[j]]] += 1\n",
    "    return [float(correct[i]) / total[i] if total[i] > 0. else 0.\n",
    "            for i in range(1, _nb_samples_per_class + 1)]\n",
    "last_logged_ep=0\n",
    "\n",
    "@tf.function\n",
    "def trainstep(model, data_generator, optimizer):\n",
    "    image, label = data_generator.generate_batch(\"train\",\n",
    "                                                 _batch_size)\n",
    "    images = tf.reshape(image, (_batch_size,-1,_input_width,_input_height,3))\n",
    "    one_hot_target = tf.one_hot(label, _nb_classes, axis=-1)\n",
    "    offset_target_var = tf.concat([tf.zeros_like(tf.expand_dims(\n",
    "        one_hot_target[:, 0], 1)), one_hot_target[:, :-1]], axis=1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model([images, offset_target_var])\n",
    "        loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                            labels=one_hot_target,\n",
    "                            logits=output\n",
    "                        ),\n",
    "                        axis=1)\n",
    "                  )\n",
    "        grads, _ = tf.clip_by_global_norm(\n",
    "            tape.gradient(loss, model.trainable_variables),\n",
    "            50)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train(model, data_genarator, _start_iterations, _iterations, _learning_rate, cell, _batch_size, _nb_classes, save_dir):\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=_learning_rate)\n",
    "    print(\"1st\\t2nd\\t3rd\\t4th\\t5th\\t6th\\t7th\\t8th\\t9th\\t10th\\tbatch\\tloss\\tdt\")\n",
    "    logdir = f\"{save_dir}/{dataset}/{cell}/{_learning_rate}/{exp_no}/logs\"\n",
    "    summary_writer = tf.summary.create_file_writer(logdir)\n",
    "    dt = datetime.now()\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for ep in range(_start_iterations, _iterations):\n",
    "        if ep % summary_interval == 0:\n",
    "            image, label = data_generator.generate_batch(\"train\",\n",
    "                                                         _batch_size)\n",
    "            images = tf.reshape(image, (_batch_size,-1,_input_width,_input_height,3))\n",
    "            one_hot_target = tf.one_hot(label, _nb_classes, axis=-1)\n",
    "            offset_target_var = tf.concat([tf.zeros_like(tf.expand_dims(\n",
    "                one_hot_target[:, 0], 1)), one_hot_target[:, :-1]], axis=1)\n",
    "            output = model([images, offset_target_var])\n",
    "            loss = tf.reduce_mean(\n",
    "                        tf.reduce_sum(\n",
    "                            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                labels=one_hot_target,\n",
    "                                logits=output),\n",
    "                            axis=1))\n",
    "            accuracy = metric_accuracy(_nb_classes, _nb_samples_per_class, label, output)\n",
    "            accuracies.append((ep,accuracy))\n",
    "            dt = datetime.now() - dt\n",
    "\n",
    "            for accu in accuracy:\n",
    "                print('%.4f' % accu, end='\\t')\n",
    "            print('%d\\t%.4f\\t%.4f' % (ep, loss, dt.total_seconds()))\n",
    "            train_loss(loss)\n",
    "            losses.append((ep,train_loss.result()))\n",
    "\n",
    "            dt = datetime.now()\n",
    "        if ep % checkpt_write_interval == 1 and ep > 0:\n",
    "            model.save_weights(f\"{save_dir}/{dataset}/{cell}/{_learning_rate}/{exp_no}\" + \"/model.\")\n",
    "            with open(f\"{save_dir}/{dataset}/{cell}/{_learning_rate}/{exp_no}\" + \"/model.iteration\", 'w') as f:\n",
    "                _start_iterations =  f.write(str(ep))\n",
    "            with summary_writer.as_default():\n",
    "              for ep_idx, accuracy in accuracies:\n",
    "                for i, accu in enumerate(accuracy):\n",
    "                    tf.summary.scalar(f'train_acc_{i}',\n",
    "                                      accu,\n",
    "                                      step=ep_idx)\n",
    "              for ep_idx, loss_res in losses:\n",
    "                tf.summary.scalar('train_loss',\n",
    "                                  train_loss.result(),\n",
    "                                  step=ep_idx)\n",
    "            last_logged_ep=ep\n",
    "            accuracies=[]\n",
    "            losses=[]\n",
    "        loss = trainstep(model, data_generator, optimizer)\n",
    "        train_loss(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Vkm4cW3fRpns"
   },
   "outputs": [],
   "source": [
    "def create_one_hot_model_convolutional(image_size,\n",
    "                                       extra_channel,\n",
    "                                       output_size,\n",
    "                                       batch_size,\n",
    "                                       cell,\n",
    "                                       cnn):\n",
    "    labels = tf.keras.layers.Input([None] + extra_channel,\n",
    "                                   batch_size=batch_size)\n",
    "    images = tf.keras.layers.Input([None] + image_size,\n",
    "                                   batch_size=batch_size)\n",
    "    labels0 = tf.stop_gradient(labels)\n",
    "    images0 = tf.stop_gradient(images)\n",
    "    resnet = tf.keras.applications.EfficientNetB0(\n",
    "                                                    include_top=False, weights='imagenet',\n",
    "                                                    input_shape=(_input_width,_input_height,3)\n",
    "                                                  )\n",
    "    cnn_timeseries = tf.keras.layers.TimeDistributed(resnet, trainable=False)\n",
    "    flatten = tf.keras.layers.Flatten()\n",
    "    flatten_timeseries = tf.keras.layers.TimeDistributed(flatten)\n",
    "    dropout = tf.keras.layers.Dropout(rate=0.4)\n",
    "    dropout_timeseries = tf.keras.layers.TimeDistributed(dropout)\n",
    "    linear = tf.keras.layers.Dense(1600)\n",
    "    linear_timeseries = tf.keras.layers.TimeDistributed(linear)\n",
    "    cell = create_cell(cell,\n",
    "                       output_size,\n",
    "                       100,\n",
    "                       128,\n",
    "                       20,\n",
    "                       10)\n",
    "\n",
    "    initial_state = cell.get_initial_state(batch_size=batch_size,\n",
    "                                           dtype=tf.float32)\n",
    "    rnn = tf.keras.layers.RNN(cell, return_sequences=True)\n",
    "    cnn_out = cnn_timeseries(images0)\n",
    "    flatten_out = flatten_timeseries(cnn_out)\n",
    "    dropout_out = dropout_timeseries(flatten_out, training=True)\n",
    "    linear_out = linear_timeseries(dropout_out)\n",
    "    cnn_out_plus_labels = tf.concat([linear_out, labels0], axis=-1)\n",
    "    y1 = rnn(cnn_out_plus_labels, initial_state=initial_state)\n",
    "    y2 = tf.keras.layers.Dense(output_size)(y1)\n",
    "    y3 = tf.keras.layers.Softmax()(y2)\n",
    "    model = tf.keras.Model([images, labels], y3)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a5o0U0r_s6Hp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = create_one_hot_model_convolutional(img_shape,\n",
    "                                           [5],\n",
    "                                           5,\n",
    "                                           _batch_size,\n",
    "                                           cell,\n",
    "                                          '4layerConv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTyj1RgejzGr"
   },
   "outputs": [],
   "source": [
    "ds_root = f'/content/datasets/Records/{dataset}'\n",
    "data_generator = DatasetGenerator(data_folder=ds_root,\n",
    "                                  splits=splits,\n",
    "                                  nb_samples_per_class=nb_samples_per_class,\n",
    "                                  img_size=img_size,\n",
    "                                  colorspace=colorspace,\n",
    "                                  pre_scale=(_input_width,_input_height),\n",
    "                                  augment=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBxlTi-VXK6d"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha-DjqvdlpQn"
   },
   "outputs": [],
   "source": [
    "model.load_weights(f\"{save_dir}/{dataset}/{cell}/{learning_rate}/{exp_no}\" + \"/model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6doSPUFJi725"
   },
   "outputs": [],
   "source": [
    "b1 = data_generator.generate_batch('train', _batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgixJwzOi9gX"
   },
   "outputs": [],
   "source": [
    "plt.imshow(tf.reshape(b1[0][0,0,:],(_input_width,_input_height,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XJsit2RxQhu"
   },
   "outputs": [],
   "source": [
    "train(model, data_generator, _start_iterations, _iterations, _learning_rate, cell, _batch_size, _nb_classes, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiLX2A5-JRcR"
   },
   "outputs": [],
   "source": [
    "def create_4layer_conv(image_size):\n",
    "    in_image = tf.keras.layers.Input(image_size)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(in_image)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    for i in range(3):\n",
    "        with tf.name_scope(f\"convbn_layer{i}\"):\n",
    "            x = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    cnn_model = tf.keras.Model(in_image, x)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op_D5ijiLZd7"
   },
   "outputs": [],
   "source": [
    "def create_4layer_deconv(image_size):\n",
    "    in_image = tf.keras.layers.Input(1600)\n",
    "    x = tf.keras.layers.Dense(np.prod([40, 40, 64]))(in_image)\n",
    "    x = tf.reshape(x,(40, 40, 64))\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), padding='SAME')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    for i in range(3):\n",
    "        with tf.name_scope(f\"convbn_layer{i}\"):\n",
    "            x = tf.keras.layers.Conv2DTranspose(64, (3, 3), padding='SAME')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    cnn_model = tf.keras.Model(in_image, x)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pByqRe1L6wl"
   },
   "outputs": [],
   "source": [
    "encoder = create_4layer_conv((40,40,3))\n",
    "bottleneck = tf.keras.layers.Dense(1600)\n",
    "decoder = create_4layer_deconv((40,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wyk1dcEiMAeu"
   },
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP0ZJ50ylCBy"
   },
   "outputs": [],
   "source": [
    "!cp -r ./Experiments_New/Convolutional4L/ /content/drive/MyDrive/Documents/MSC/Courses/Thesis/Experiments_New/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbpcyvMjPtoFrYwM9Fa6Fu",
   "collapsed_sections": [],
   "name": "Copy of metalearning-vggflower-convdnc-2.ipynb",
   "provenance": [
    {
     "file_id": "1JKdOELV701ib0_97LeDCh9UEbwtrM8Zr",
     "timestamp": 1621690685999
    },
    {
     "file_id": "1HbfSGLbxCCRYib5kOlY-p_vTbaMl3eiE",
     "timestamp": 1621689548161
    },
    {
     "file_id": "1gHbIqMYLVGmYYc3_p6CtLIZU8G4cvEeX",
     "timestamp": 1621526390826
    },
    {
     "file_id": "156Bx_KS9DiLJn9x-oEOVgQWHnbU30Vme",
     "timestamp": 1618157399854
    },
    {
     "file_id": "1rhtKSBuF3G-befB-aaKjhRAritmqXPJc",
     "timestamp": 1617887783317
    },
    {
     "file_id": "11yQrdhhEGTZSkwEYsCT9V_e7ld98N-jk",
     "timestamp": 1617862091638
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
