{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_no = 1\n",
    "batch_size = _batch_size = 32\n",
    "nb_classes = _nb_classes = 5\n",
    "nb_samples_per_class = _nb_samples_per_class = 10\n",
    "_input_height = _input_width = 40\n",
    "colorspace = 'RGB'\n",
    "channels = {'RGB':3, 'L':1}\n",
    "_iterations = 100000\n",
    "\n",
    "img_size = (_input_height, _input_width)\n",
    "img_shape = [_input_height, _input_width, channels[colorspace]]\n",
    "\n",
    "input_size = _input_height * _input_width * channels[colorspace]\n",
    "cell = 'DNC'\n",
    "nb_reads = _nb_reads = 1\n",
    "controller_size = _controller_size = 100\n",
    "memory_size = _memory_locations = 128\n",
    "memory_dim = ar_memory_word_size = 20\n",
    "summary_interval = 1\n",
    "checkpt_write_interval = 1000\n",
    "dataset = 'vgg_flower'\n",
    "splits=[70,15,15]\n",
    "\n",
    "learning_rate = _learning_rate = 1e-3\n",
    "start=0\n",
    "save_dir='./Experiments_New/Convolutional4layer'\n",
    "_start_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./metalearning')\n",
    "os.environ[\"RECORDS\"]=\"./datasets/Records\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metalearning_tasks.fixed_shot_classification_v2 import DatasetGenerator\n",
    "from models.model_builder import create_one_hot_model_convolutional, create_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_error = tf.keras.metrics.Mean('train_error', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_accuracy(_nb_classes,_nb_samples_per_class,labels, outputs):\n",
    "    seq_length = _nb_classes * _nb_samples_per_class\n",
    "    outputs = np.argmax(outputs, axis=-1)\n",
    "    correct = [0] * seq_length\n",
    "    total = [0] * seq_length\n",
    "    for i in range(np.shape(labels)[0]):\n",
    "        label = labels[i]\n",
    "        output = outputs[i]\n",
    "        class_count = {}\n",
    "        for j in range(seq_length):\n",
    "            class_count[label[j]] = class_count.get(label[j], 0) + 1\n",
    "            total[class_count[label[j]]] += 1\n",
    "            if label[j] == output[j]:\n",
    "                correct[class_count[label[j]]] += 1\n",
    "    return [float(correct[i]) / total[i] if total[i] > 0. else 0.\n",
    "            for i in range(1, _nb_samples_per_class + 1)]\n",
    "last_logged_ep=0\n",
    "\n",
    "@tf.function\n",
    "def trainstep(model, data_generator, optimizer):\n",
    "    image, label = data_generator.generate_batch(\"train\",\n",
    "                                                 _batch_size)\n",
    "    images = tf.reshape(image, (_batch_size,-1,40,40,3))\n",
    "    one_hot_target = tf.one_hot(label, _nb_classes, axis=-1)\n",
    "    offset_target_var = tf.concat([tf.zeros_like(tf.expand_dims(\n",
    "        one_hot_target[:, 0], 1)), one_hot_target[:, :-1]], axis=1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model([images, offset_target_var])\n",
    "        loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                            labels=one_hot_target,\n",
    "                            logits=output\n",
    "                        ),\n",
    "                        axis=1)\n",
    "                  )\n",
    "        grads, _ = tf.clip_by_global_norm(\n",
    "            tape.gradient(loss, model.trainable_variables),\n",
    "            50)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train(model, data_genarator, _start_iterations, _iterations, _learning_rate, cell, _batch_size, _nb_classes, save_dir):\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=_learning_rate)\n",
    "    print(\"1st\\t2nd\\t3rd\\t4th\\t5th\\t6th\\t7th\\t8th\\t9th\\t10th\\tbatch\\tloss\\tdt\")\n",
    "    logdir = f\"{save_dir}/{dataset}/{cell}/{_learning_rate}/{exp_no}/logs\"\n",
    "    summary_writer = tf.summary.create_file_writer(logdir)\n",
    "    dt = datetime.now()\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for ep in range(_start_iterations, _iterations):\n",
    "        if ep % summary_interval == 0:\n",
    "            image, label = data_generator.generate_batch(\"train\",\n",
    "                                                         _batch_size)\n",
    "            images = tf.reshape(image, (_batch_size,-1,40,40,3))\n",
    "            one_hot_target = tf.one_hot(label, _nb_classes, axis=-1)\n",
    "            offset_target_var = tf.concat([tf.zeros_like(tf.expand_dims(\n",
    "                one_hot_target[:, 0], 1)), one_hot_target[:, :-1]], axis=1)\n",
    "            output = model([images, offset_target_var])\n",
    "            loss = tf.reduce_mean(\n",
    "                        tf.reduce_sum(\n",
    "                            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                labels=one_hot_target,\n",
    "                                logits=output),\n",
    "                            axis=1))\n",
    "            accuracy = metric_accuracy(_nb_classes, _nb_samples_per_class, label, output)\n",
    "            accuracies.append((ep,accuracy))\n",
    "            dt = datetime.now() - dt\n",
    "\n",
    "            for accu in accuracy:\n",
    "                print('%.4f' % accu, end='\\t')\n",
    "            print('%d\\t%.4f\\t%.4f' % (ep, loss, dt.total_seconds()))\n",
    "            train_loss(loss)\n",
    "            losses.append((ep,train_loss.result()))\n",
    "\n",
    "            dt = datetime.now()\n",
    "        if ep % checkpt_write_interval == 1 and ep > 0:\n",
    "            model.save_weights(f\"{save_dir}/{dataset}/{cell}/{_learning_rate}/{exp_no}\" + \"/model.\")\n",
    "            with open(f\"{save_dir}/{dataset}/{cell}/{_learning_rate}/{exp_no}\" + \"/model.iteration\", 'w') as f:\n",
    "                _start_iterations =  f.write(str(ep))\n",
    "            with summary_writer.as_default():\n",
    "              for ep_idx, accuracy in accuracies:\n",
    "                for i, accu in enumerate(accuracy):\n",
    "                    tf.summary.scalar(f'train_acc_{i}',\n",
    "                                      accu,\n",
    "                                      step=ep_idx)\n",
    "              for ep_idx, loss_res in losses:\n",
    "                tf.summary.scalar('train_loss',\n",
    "                                  train_loss.result(),\n",
    "                                  step=ep_idx)\n",
    "            last_logged_ep=ep\n",
    "            accuracies=[]\n",
    "            losses=[]\n",
    "        loss = trainstep(model, data_generator, optimizer)\n",
    "        train_loss(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_one_hot_model_convolutional(img_shape,\n",
    "                                           [5],\n",
    "                                           5,\n",
    "                                           _batch_size,\n",
    "                                           cell,\n",
    "                                          '4layerConv')\n",
    "ds_root = f'./datasets/Records/{dataset}'\n",
    "data_generator = DatasetGenerator(data_folder=ds_root,\n",
    "                                  splits=splits,\n",
    "                                  nb_samples_per_class=nb_samples_per_class,\n",
    "                                  img_size=img_size,\n",
    "                                  colorspace=colorspace,\n",
    "                                  pre_scale=(60,60),\n",
    "                                  augment=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(32, None, 40, 40,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stop_gradient_1 (TFOpLambda) (32, None, 40, 40, 3 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (32, None, 102400)   113600      tf.stop_gradient_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (32, None, 102400)   0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(32, None, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (32, None, 1600)     163841600   time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.stop_gradient (TFOpLambda)   (32, None, 5)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (32, None, 1605)     0           time_distributed_2[0][0]         \n",
      "                                                                 tf.stop_gradient[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "rnn (RNN)                       (32, None, 5)        699893      tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, None, 5)        30          rnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (32, None, 5)        0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 164,655,123\n",
      "Trainable params: 164,654,611\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = data_generator.generate_batch('train', _batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff11846a8e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.reshape(b1[0][0,0,:],(40,40,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st\t2nd\t3rd\t4th\t5th\t6th\t7th\t8th\t9th\t10th\tbatch\tloss\tdt\n",
      "0.1938\t0.1375\t0.1938\t0.2125\t0.2115\t0.1933\t0.1739\t0.1641\t0.1909\t0.2308\t0\t80.5048\t4.0454\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2025\t0.2000\t0.1931\t0.1860\t0.2170\t0.2308\t1\t81.1629\t18.3632\n",
      "0.1750\t0.1750\t0.1938\t0.1761\t0.1871\t0.1688\t0.2192\t0.1846\t0.1491\t0.2222\t2\t80.9375\t14.0853\n",
      "0.2000\t0.2000\t0.2000\t0.2025\t0.1987\t0.1948\t0.2098\t0.2214\t0.2281\t0.2353\t3\t80.9618\t13.7003\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.1899\t0.1854\t0.1818\t0.1938\t0.1842\t0.1848\t4\t80.8847\t13.7948\n",
      "0.2000\t0.2000\t0.2013\t0.2025\t0.2038\t0.2026\t0.2109\t0.2121\t0.2119\t0.2553\t5\t80.7735\t13.7891\n",
      "0.2000\t0.1938\t0.1950\t0.1950\t0.1923\t0.1959\t0.2000\t0.2000\t0.2182\t0.2222\t6\t80.6805\t13.7999\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1987\t0.1948\t0.2041\t0.2248\t0.2130\t0.2209\t7\t80.6868\t13.8410\n",
      "0.1812\t0.2000\t0.2000\t0.2000\t0.1911\t0.1948\t0.2000\t0.1923\t0.2124\t0.1910\t8\t80.7969\t13.7627\n",
      "0.1688\t0.2000\t0.2000\t0.2000\t0.1962\t0.1948\t0.1871\t0.1890\t0.2054\t0.1758\t9\t80.8701\t13.7748\n",
      "0.2062\t0.2000\t0.2000\t0.2025\t0.1923\t0.1854\t0.1986\t0.1818\t0.1981\t0.2273\t10\t80.9106\t13.7405\n",
      "0.2250\t0.2000\t0.1950\t0.1950\t0.1899\t0.1923\t0.1946\t0.2248\t0.2232\t0.2381\t11\t80.8804\t13.7674\n",
      "0.2062\t0.2000\t0.2000\t0.2000\t0.2013\t0.1935\t0.1879\t0.1679\t0.1622\t0.1392\t12\t80.9587\t13.7513\n",
      "0.2313\t0.1938\t0.2000\t0.2000\t0.2000\t0.2038\t0.2041\t0.2109\t0.2130\t0.2093\t13\t80.6730\t13.8064\n",
      "0.2000\t0.2000\t0.2000\t0.1962\t0.1987\t0.2013\t0.1915\t0.1953\t0.1909\t0.1848\t14\t80.7597\t13.8302\n",
      "0.2000\t0.2000\t0.2000\t0.1950\t0.1911\t0.1935\t0.1921\t0.2057\t0.2193\t0.2308\t15\t80.8575\t13.7750\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2013\t0.2000\t0.2138\t0.2348\t0.2190\t0.2353\t16\t80.9522\t13.8283\n",
      "0.2000\t0.2013\t0.2013\t0.2013\t0.2000\t0.2053\t0.2113\t0.2031\t0.2018\t0.2088\t17\t80.7050\t13.8592\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1987\t0.1974\t0.1849\t0.1838\t0.1724\t0.1477\t18\t80.9764\t13.7949\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2000\t0.2013\t0.1837\t0.1832\t0.1826\t0.1758\t19\t80.7767\t13.7734\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1975\t0.1867\t0.1849\t0.1778\t0.1818\t0.1744\t20\t80.7087\t13.7815\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2000\t0.2067\t0.2057\t0.2000\t0.1927\t0.1684\t21\t80.6677\t13.8062\n",
      "0.2000\t0.2000\t0.2013\t0.1975\t0.1987\t0.2013\t0.1871\t0.1783\t0.1875\t0.2235\t22\t80.7392\t13.7612\n",
      "0.2000\t0.2000\t0.2013\t0.2025\t0.2025\t0.2026\t0.2083\t0.2109\t0.2143\t0.2247\t23\t80.5311\t13.8588\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2025\t0.2039\t0.1958\t0.1742\t0.1622\t0.2069\t24\t80.6143\t13.8840\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2038\t0.2053\t0.2000\t0.1935\t0.1966\t0.1848\t25\t80.6548\t13.8474\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2038\t0.1974\t0.1972\t0.1940\t0.1930\t0.1548\t26\t80.6704\t13.7278\n",
      "0.2000\t0.2000\t0.2013\t0.2013\t0.1987\t0.1987\t0.2000\t0.2101\t0.2066\t0.1705\t27\t80.6051\t13.7514\n",
      "0.2000\t0.2000\t0.1950\t0.1950\t0.1962\t0.2027\t0.2071\t0.2000\t0.2054\t0.2111\t28\t80.7478\t13.7844\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.1962\t0.1987\t0.1944\t0.2077\t0.2054\t0.2273\t29\t80.6341\t13.7060\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2013\t0.1921\t0.1901\t0.1953\t0.1913\t0.2111\t30\t80.7160\t13.7291\n",
      "0.1688\t0.2000\t0.2562\t0.2342\t0.2357\t0.2053\t0.2083\t0.1783\t0.1681\t0.1573\t31\t80.5697\t13.8760\n",
      "0.1812\t0.2062\t0.2000\t0.2013\t0.2025\t0.2065\t0.2095\t0.2188\t0.2143\t0.2135\t32\t80.4908\t13.6875\n",
      "0.1875\t0.2062\t0.2000\t0.2000\t0.2025\t0.2078\t0.2000\t0.2077\t0.2000\t0.1910\t33\t80.6869\t13.7678\n",
      "0.2313\t0.2000\t0.2000\t0.2000\t0.2025\t0.2078\t0.2109\t0.2188\t0.2281\t0.1848\t34\t80.6541\t13.9551\n",
      "0.1938\t0.1875\t0.2000\t0.2000\t0.2013\t0.2000\t0.2041\t0.1908\t0.1947\t0.1807\t35\t80.7046\t13.7814\n",
      "0.2062\t0.1875\t0.1875\t0.1625\t0.2025\t0.2194\t0.2183\t0.2063\t0.2342\t0.2093\t36\t80.7026\t13.7812\n",
      "0.2000\t0.2000\t0.2000\t0.1962\t0.1987\t0.2026\t0.1958\t0.2090\t0.1966\t0.1910\t37\t80.6550\t13.7582\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2000\t0.2013\t0.2039\t0.1838\t0.1681\t0.1529\t38\t80.7275\t13.8727\n",
      "0.2000\t0.2000\t0.1950\t0.1950\t0.1975\t0.2013\t0.1915\t0.2031\t0.1942\t0.1977\t39\t80.5422\t13.7090\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2013\t0.2013\t0.2028\t0.2000\t0.1909\t0.1905\t40\t80.4849\t13.7915\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1962\t0.2013\t0.2081\t0.2061\t0.2018\t0.1910\t41\t80.6352\t13.7696\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2013\t0.2078\t0.2123\t0.1923\t0.1892\t0.1959\t42\t80.6287\t13.8123\n",
      "0.2000\t0.1875\t0.2250\t0.2013\t0.1783\t0.1961\t0.1931\t0.1969\t0.2202\t0.2184\t43\t80.3671\t13.7656\n",
      "0.2188\t0.2125\t0.2000\t0.2000\t0.1899\t0.1883\t0.1944\t0.1971\t0.2037\t0.1954\t44\t80.6224\t13.7648\n",
      "0.1750\t0.2000\t0.2025\t0.2038\t0.2051\t0.2162\t0.2263\t0.2222\t0.2069\t0.1798\t45\t80.5982\t13.8814\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1987\t0.1987\t0.1958\t0.1926\t0.2105\t0.1957\t46\t80.6534\t13.7307\n",
      "0.1688\t0.2000\t0.2000\t0.2000\t0.2025\t0.2067\t0.1986\t0.1955\t0.1892\t0.1685\t47\t80.7477\t13.7104\n",
      "0.1812\t0.2000\t0.2000\t0.1962\t0.1987\t0.2026\t0.2123\t0.2222\t0.2232\t0.2222\t48\t80.5598\t13.9519\n",
      "0.2000\t0.2013\t0.2013\t0.2013\t0.2013\t0.2078\t0.2254\t0.2326\t0.1963\t0.1591\t49\t80.6262\t13.8273\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1975\t0.1961\t0.2083\t0.2197\t0.2261\t0.2333\t50\t80.6085\t13.8852\n",
      "0.2000\t0.2000\t0.2000\t0.1962\t0.1975\t0.1921\t0.1915\t0.2031\t0.2075\t0.1765\t51\t80.6338\t13.7880\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.1987\t0.2013\t0.2083\t0.2148\t0.2051\t0.1868\t52\t80.5960\t13.8200\n",
      "0.2000\t0.2000\t0.2013\t0.2013\t0.2092\t0.2148\t0.2177\t0.2197\t0.2155\t0.2418\t53\t80.4977\t13.6830\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.1962\t0.2000\t0.1946\t0.1923\t0.1947\t0.1882\t54\t80.6010\t13.8099\n",
      "0.2000\t0.2000\t0.2000\t0.1950\t0.1935\t0.1892\t0.1724\t0.1783\t0.1944\t0.2065\t55\t80.7383\t13.9352\n",
      "0.2000\t0.2013\t0.2013\t0.2013\t0.1987\t0.1974\t0.2014\t0.2029\t0.1930\t0.1778\t56\t80.4722\t13.7836\n",
      "0.2000\t0.2000\t0.2013\t0.2025\t0.2065\t0.2133\t0.2263\t0.2480\t0.2547\t0.2688\t57\t80.6151\t13.7562\n",
      "0.2000\t0.2000\t0.2000\t0.1950\t0.1871\t0.1854\t0.1824\t0.1846\t0.1667\t0.1724\t58\t80.6988\t13.7559\n",
      "0.2000\t0.2000\t0.2013\t0.2013\t0.2051\t0.2162\t0.2190\t0.2160\t0.2385\t0.2500\t59\t80.4795\t13.7588\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1975\t0.2000\t0.2041\t0.1923\t0.2000\t0.2386\t60\t80.5278\t13.7092\n",
      "0.2000\t0.2000\t0.2000\t0.1950\t0.1987\t0.1987\t0.2098\t0.2197\t0.2328\t0.2500\t61\t80.5583\t13.8123\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2013\t0.1883\t0.1986\t0.2061\t0.2124\t0.2135\t62\t80.5453\t13.9047\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.1975\t0.1974\t0.2083\t0.2105\t0.2232\t0.2727\t63\t80.6273\t13.8299\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2013\t0.2051\t0.2000\t0.2137\t0.2155\t0.2247\t64\t80.5407\t13.7124\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2013\t0.2078\t0.1973\t0.2016\t0.2018\t0.1977\t65\t80.6774\t13.7950\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2025\t0.2051\t0.1944\t0.2061\t0.2072\t0.2258\t66\t80.5974\t13.7888\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2038\t0.2051\t0.2105\t0.2090\t0.1947\t0.2045\t67\t80.7658\t13.7390\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.2025\t0.2051\t0.2081\t0.2077\t0.2054\t0.1889\t68\t80.5286\t13.7963\n",
      "0.2000\t0.2000\t0.2000\t0.2025\t0.2025\t0.1948\t0.1931\t0.1825\t0.2000\t0.1889\t69\t80.5820\t13.8442\n",
      "0.2000\t0.2000\t0.2013\t0.2013\t0.2025\t0.2051\t0.2138\t0.2015\t0.2232\t0.2414\t70\t80.5414\t13.7060\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1923\t0.1935\t0.2113\t0.2171\t0.2150\t0.2308\t71\t80.4089\t13.8006\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2000\t0.2000\t0.1958\t0.1860\t0.1852\t0.1860\t72\t80.5532\t13.8094\n",
      "0.2000\t0.2000\t0.2000\t0.2013\t0.1987\t0.2095\t0.2014\t0.2148\t0.2348\t0.2674\t73\t80.3970\t13.9193\n",
      "0.2000\t0.2000\t0.2000\t0.2000\t0.2000\t0.1911\t0.1905\t0.1811\t0.1818\t0.1839\t74\t80.7198\t13.7800\n",
      "0.2062\t0.2000\t0.2000\t0.2000\t0.2013\t0.1987\t0.2027\t0.2171\t0.2281\t0.2268\t75\t80.4212\t13.8199\n",
      "0.2250\t0.2000\t0.2013\t0.1987\t0.1987\t0.1974\t0.1905\t0.1716\t0.1560\t0.1250\t76\t80.6837\t13.7683\n",
      "0.2125\t0.2000\t0.2000\t0.2013\t0.2013\t0.1961\t0.1944\t0.1970\t0.1869\t0.1647\t77\t80.7511\t13.7854\n",
      "0.2125\t0.2000\t0.2013\t0.2013\t0.2013\t0.2119\t0.2083\t0.2049\t0.2243\t0.2299\t78\t80.5132\t13.7597\n",
      "0.2188\t0.2000\t0.2000\t0.2000\t0.2025\t0.2053\t0.2174\t0.2214\t0.1792\t0.1556\t79\t80.7022\t13.8307\n",
      "0.2000\t0.2000\t0.1938\t0.1950\t0.1962\t0.2053\t0.1915\t0.2131\t0.2150\t0.2093\t80\t80.5412\t13.8019\n",
      "0.2313\t0.2188\t0.2000\t0.2000\t0.2025\t0.2078\t0.2028\t0.2061\t0.1947\t0.2118\t81\t80.5027\t13.7401\n",
      "0.1812\t0.1812\t0.2062\t0.2013\t0.2013\t0.2026\t0.2123\t0.2121\t0.2130\t0.2262\t82\t80.5769\t13.9659\n",
      "0.2687\t0.2562\t0.2125\t0.2062\t0.2062\t0.1950\t0.1678\t0.1301\t0.1373\t0.1279\t83\t80.6310\t13.7581\n",
      "0.1437\t0.2125\t0.2075\t0.1975\t0.1935\t0.2053\t0.2123\t0.2090\t0.2054\t0.2198\t84\t80.5770\t13.7517\n",
      "0.1750\t0.1625\t0.1635\t0.2075\t0.2078\t0.2133\t0.2254\t0.2348\t0.2252\t0.2500\t85\t80.5873\t13.8208\n",
      "0.2125\t0.1688\t0.1875\t0.2013\t0.1962\t0.2013\t0.1806\t0.1955\t0.1636\t0.1413\t86\t80.6386\t13.8421\n",
      "0.2437\t0.2000\t0.2062\t0.1950\t0.2089\t0.2078\t0.2199\t0.1923\t0.1770\t0.1868\t87\t80.6937\t13.9059\n",
      "0.2188\t0.1625\t0.1698\t0.1950\t0.2237\t0.2055\t0.1898\t0.2083\t0.1765\t0.1605\t88\t80.6809\t13.8199\n",
      "0.2125\t0.2188\t0.2562\t0.2000\t0.1887\t0.1895\t0.1837\t0.1705\t0.1441\t0.1474\t89\t80.6764\t13.7285\n",
      "0.2125\t0.2313\t0.2562\t0.2313\t0.2166\t0.2157\t0.2055\t0.1639\t0.1667\t0.1348\t90\t80.5161\t13.7417\n",
      "0.1750\t0.2125\t0.2062\t0.1875\t0.1835\t0.2081\t0.1929\t0.1719\t0.1826\t0.1744\t91\t80.6087\t13.8496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2000\t0.2000\t0.1938\t0.1824\t0.1962\t0.2078\t0.2109\t0.1955\t0.2035\t0.1818\t92\t80.5088\t13.8346\n",
      "0.1688\t0.2075\t0.2390\t0.2278\t0.2051\t0.1733\t0.1761\t0.1938\t0.1698\t0.1744\t93\t80.6482\t13.8069\n",
      "0.1750\t0.1938\t0.2264\t0.1950\t0.1456\t0.1765\t0.2014\t0.2045\t0.1983\t0.2111\t94\t80.6031\t13.8604\n",
      "0.2062\t0.1938\t0.2000\t0.2250\t0.2188\t0.2267\t0.1971\t0.1803\t0.1635\t0.1882\t95\t80.5981\t13.7894\n",
      "0.2062\t0.2500\t0.2062\t0.2264\t0.2138\t0.2013\t0.1892\t0.1799\t0.1966\t0.2045\t96\t80.5727\t13.7120\n",
      "0.1938\t0.1938\t0.1938\t0.2278\t0.1975\t0.1908\t0.1901\t0.1832\t0.1786\t0.2021\t97\t80.6076\t13.8088\n",
      "0.2188\t0.1688\t0.1812\t0.1887\t0.1847\t0.2157\t0.2083\t0.2137\t0.2321\t0.2471\t98\t80.6636\t13.9029\n",
      "0.1938\t0.2062\t0.2437\t0.2342\t0.2102\t0.1859\t0.1862\t0.1880\t0.1842\t0.1839\t99\t80.5880\t13.7357\n",
      "0.2125\t0.2188\t0.2500\t0.2075\t0.1772\t0.1921\t0.1857\t0.1984\t0.1759\t0.1818\t100\t80.6235\t13.7581\n",
      "0.2125\t0.2500\t0.2313\t0.1938\t0.1938\t0.1824\t0.1918\t0.1875\t0.1909\t0.2135\t101\t80.6465\t13.8820\n",
      "0.2125\t0.2250\t0.2437\t0.2437\t0.2215\t0.1908\t0.2174\t0.2061\t0.2385\t0.2222\t102\t80.5758\t13.7891\n",
      "0.1938\t0.1625\t0.1500\t0.2062\t0.2308\t0.2053\t0.1931\t0.2061\t0.2364\t0.2716\t103\t80.6255\t13.7617\n",
      "0.2062\t0.2000\t0.1875\t0.1572\t0.1911\t0.2185\t0.2138\t0.1970\t0.1835\t0.2043\t104\t80.6079\t13.8472\n",
      "0.1875\t0.1938\t0.2125\t0.1625\t0.1731\t0.1933\t0.1875\t0.2030\t0.2056\t0.2000\t105\t80.8643\t13.9759\n",
      "0.2000\t0.1938\t0.1875\t0.1562\t0.1656\t0.2013\t0.1959\t0.2074\t0.1930\t0.1724\t106\t80.6344\t13.7372\n",
      "0.1938\t0.2000\t0.2062\t0.2327\t0.2342\t0.2185\t0.1918\t0.2137\t0.2170\t0.1882\t107\t80.5367\t13.7805\n",
      "0.2000\t0.2125\t0.1635\t0.1465\t0.1474\t0.1961\t0.2014\t0.2033\t0.2475\t0.2093\t108\t80.6608\t13.8450\n",
      "0.2000\t0.1875\t0.1875\t0.1824\t0.2089\t0.1948\t0.2238\t0.2283\t0.2617\t0.2353\t109\t80.5484\t13.8362\n",
      "0.2000\t0.2125\t0.2000\t0.1835\t0.2025\t0.2185\t0.2098\t0.2030\t0.2124\t0.2262\t110\t80.5174\t13.7940\n",
      "0.1938\t0.1875\t0.2201\t0.2215\t0.2194\t0.1867\t0.2014\t0.1860\t0.1927\t0.1628\t111\t80.7936\t13.8452\n",
      "0.2375\t0.2125\t0.2000\t0.2215\t0.2115\t0.2273\t0.2245\t0.2362\t0.2091\t0.2073\t112\t80.5486\t13.8447\n",
      "0.1938\t0.1938\t0.2375\t0.2562\t0.1887\t0.2039\t0.1761\t0.1875\t0.2300\t0.2048\t113\t80.4802\t13.8054\n",
      "0.2062\t0.2000\t0.1938\t0.1625\t0.2025\t0.2067\t0.1972\t0.2256\t0.2261\t0.2151\t114\t80.5638\t13.8075\n",
      "0.2250\t0.1250\t0.1812\t0.1887\t0.2102\t0.2039\t0.2071\t0.1984\t0.1786\t0.1789\t115\t80.5908\t13.7346\n",
      "0.1750\t0.2375\t0.2687\t0.2342\t0.2065\t0.2078\t0.2041\t0.1875\t0.1982\t0.1818\t116\t80.6481\t13.7653\n",
      "0.1625\t0.2000\t0.2000\t0.2075\t0.2293\t0.2222\t0.2254\t0.2016\t0.1560\t0.1744\t117\t80.4836\t13.6915\n",
      "0.2188\t0.1938\t0.1875\t0.1887\t0.1720\t0.1883\t0.2000\t0.1984\t0.1875\t0.2000\t118\t80.5885\t13.8754\n",
      "0.1938\t0.1688\t0.1750\t0.2201\t0.2278\t0.2000\t0.1986\t0.2063\t0.1782\t0.1923\t119\t80.5887\t13.8305\n",
      "0.2125\t0.1875\t0.1635\t0.1321\t0.1835\t0.1722\t0.1901\t0.1923\t0.2054\t0.2151\t120\t80.5196\t13.7641\n",
      "0.2125\t0.2188\t0.2375\t0.2579\t0.2468\t0.2148\t0.1901\t0.1832\t0.1402\t0.1591\t121\t80.6230\t13.8675\n",
      "0.2125\t0.1562\t0.1625\t0.1887\t0.1899\t0.1776\t0.1849\t0.1880\t0.1913\t0.2159\t122\t80.7339\t13.8551\n",
      "0.1875\t0.1562\t0.2102\t0.1975\t0.2092\t0.1946\t0.2041\t0.2197\t0.2281\t0.2366\t123\t80.5909\t13.7630\n",
      "0.2062\t0.1812\t0.2375\t0.2264\t0.2215\t0.2143\t0.1986\t0.1729\t0.1810\t0.1556\t124\t80.6670\t13.8671\n",
      "0.2062\t0.2062\t0.2062\t0.2201\t0.2468\t0.2067\t0.2098\t0.2154\t0.1651\t0.1720\t125\t80.5754\t13.8087\n"
     ]
    }
   ],
   "source": [
    "train(model, data_generator, _start_iterations, _iterations, _learning_rate, cell, _batch_size, _nb_classes, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
