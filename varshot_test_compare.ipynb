{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MREk7W_dkwsq"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import os\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./metalearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9t5Vpk_akyAQ"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "byVqiEsCkyas"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from metalearning_tasks.variable_shot_classification import DatasetGenerator\n",
    "from models.model_builder import create_string_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RXTl1nsulJEe"
   },
   "outputs": [],
   "source": [
    "exp_no = 3\n",
    "_iterations = 100000\n",
    "batch_size = _batch_size = 32\n",
    "nb_classes = _nb_classes = 5\n",
    "nb_samples_per_class = _nb_samples_per_class = 10\n",
    "_input_height = _input_width = 20\n",
    "img_size = (_input_height, _input_width)\n",
    "colorspace = 'L'\n",
    "channels = {'RGB':3, 'L':1}\n",
    "input_size = _input_height * _input_width * channels[colorspace]\n",
    "nb_reads = _nb_reads = 1\n",
    "controller_size = _controller_size = 100\n",
    "memory_size = _memory_locations = 128\n",
    "memory_dim = ar_memory_word_size = 20\n",
    "dataset = 'omniglot'\n",
    "splits=[1200,200,0]\n",
    "\n",
    "cells = {'LSTM':'LSTM','LRUold':'DNC','DNC':'DNC'}\n",
    "save_dir='./varshot'\n",
    "sizes = [5, 10, 15, 20, 25, 50, 100]\n",
    "models = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DEJMnlK6k0vE"
   },
   "outputs": [],
   "source": [
    "test_error = [tf.keras.metrics.Mean(f'error_{i}', dtype=tf.float32) for i in sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_root = f'./datasets/Records/{dataset}'\n",
    "data_generator = DatasetGenerator(data_folder=ds_root,\n",
    "                                  splits=splits,\n",
    "                                  nb_samples_per_class=nb_samples_per_class,\n",
    "                                  img_size=img_size,\n",
    "                                  colorspace=colorspace,\n",
    "                                  pre_scale=(60,60),\n",
    "                                  augment=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wrC6hCUfnwUy",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from ./varshot/LSTM/ for LSTM\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent.RNN object at 0x7f7ea9955fd0> and <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7f7e715fb520>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f7e715fb820> and <tensorflow.python.keras.layers.recurrent.RNN object at 0x7f7ea9955fd0>).\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(32, None, 425)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stop_gradient_3 (TFOpLambda) (32, None, 425)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rnn_3 (RNN)                     (32, None, 256)      698368      tf.stop_gradient_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (32, None, 25)       6425        rnn_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_3 (TFOpLambda)         [(32, None, 5), (32, 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_15 (Softmax)            (32, None, 5)        0           tf.split_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_16 (Softmax)            (32, None, 5)        0           tf.split_3[0][1]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_17 (Softmax)            (32, None, 5)        0           tf.split_3[0][2]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_18 (Softmax)            (32, None, 5)        0           tf.split_3[0][3]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_19 (Softmax)            (32, None, 5)        0           tf.split_3[0][4]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (32, None, 25)       0           softmax_15[0][0]                 \n",
      "                                                                 softmax_16[0][0]                 \n",
      "                                                                 softmax_17[0][0]                 \n",
      "                                                                 softmax_18[0][0]                 \n",
      "                                                                 softmax_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 704,793\n",
      "Trainable params: 704,793\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "loading weights from ./varshot/LRUold/ for DNC\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent.RNN object at 0x7f7e715b0ca0> and <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7f7e7157f760>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f7e715b0c70> and <tensorflow.python.keras.layers.recurrent.RNN object at 0x7f7e715b0ca0>).\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(32, None, 425)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stop_gradient_4 (TFOpLambda) (32, None, 425)      0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rnn_4 (RNN)                     (32, None, 25)       230313      tf.stop_gradient_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (32, None, 25)       650         rnn_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_4 (TFOpLambda)         [(32, None, 5), (32, 0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_20 (Softmax)            (32, None, 5)        0           tf.split_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_21 (Softmax)            (32, None, 5)        0           tf.split_4[0][1]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_22 (Softmax)            (32, None, 5)        0           tf.split_4[0][2]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_23 (Softmax)            (32, None, 5)        0           tf.split_4[0][3]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_24 (Softmax)            (32, None, 5)        0           tf.split_4[0][4]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_4 (TFOpLambda)        (32, None, 25)       0           softmax_20[0][0]                 \n",
      "                                                                 softmax_21[0][0]                 \n",
      "                                                                 softmax_22[0][0]                 \n",
      "                                                                 softmax_23[0][0]                 \n",
      "                                                                 softmax_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 230,963\n",
      "Trainable params: 230,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "loading weights from ./varshot/DNC/ for DNC\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent.RNN object at 0x7f7e715160a0> and <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7f7e71528160>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f7e714c5df0> and <tensorflow.python.keras.layers.recurrent.RNN object at 0x7f7e715160a0>).\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(32, None, 425)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stop_gradient_5 (TFOpLambda) (32, None, 425)      0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rnn_5 (RNN)                     (32, None, 25)       230313      tf.stop_gradient_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (32, None, 25)       650         rnn_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_5 (TFOpLambda)         [(32, None, 5), (32, 0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_25 (Softmax)            (32, None, 5)        0           tf.split_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_26 (Softmax)            (32, None, 5)        0           tf.split_5[0][1]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_27 (Softmax)            (32, None, 5)        0           tf.split_5[0][2]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_28 (Softmax)            (32, None, 5)        0           tf.split_5[0][3]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_29 (Softmax)            (32, None, 5)        0           tf.split_5[0][4]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_5 (TFOpLambda)        (32, None, 25)       0           softmax_25[0][0]                 \n",
      "                                                                 softmax_26[0][0]                 \n",
      "                                                                 softmax_27[0][0]                 \n",
      "                                                                 softmax_28[0][0]                 \n",
      "                                                                 softmax_29[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 230,963\n",
      "Trainable params: 230,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for folder,cell in cells.items():\n",
    "  dir = f\"{save_dir}/{folder}/\"\n",
    "  try:\n",
    "    print(f'loading weights from {dir} for {cell}')\n",
    "    model = create_string_model(\n",
    "                                input_size+25,\n",
    "                                _batch_size,\n",
    "                                cell)\n",
    "\n",
    "    model.load_weights(dir + \"/model.\")\n",
    "    models[folder] = model\n",
    "    model.summary()\n",
    "  except:\n",
    "    logging.exception(\"failed to load weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "y2QUPbFlXejw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LSTM': <tensorflow.python.keras.engine.functional.Functional at 0x7f7e71584880>,\n",
       " 'DNC': <tensorflow.python.keras.engine.functional.Functional at 0x7f7e7146de20>,\n",
       " 'LRUold': <tensorflow.python.keras.engine.functional.Functional at 0x7f7e714e6490>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelstr(pentits):\n",
    "    chars=['A','B','C','D','E']\n",
    "    strchars = [chars[pentits[idx]] for idx in range(len(pentits))]\n",
    "    return str(strchars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "tmxFD5JWoc9y"
   },
   "outputs": [],
   "source": [
    "def test(model, data_generator, sizes):\n",
    "    test_error = [[tf.keras.metrics.Mean(f'error_{s}classes_inst{i}', dtype=tf.float32) for i in [1,2,5,10]] for s in sizes]\n",
    "    print('size', end='\\t')\n",
    "    for size in sizes:\n",
    "        print('%d' % size, end='\\t\\t\\t')\n",
    "    print('')\n",
    "    print('\\t', end='')\n",
    "    for size in sizes:\n",
    "        for instance in [1,2,5,10]:\n",
    "            print(f'{instance}    ', end='')\n",
    "        print(f'', end='\\t')\n",
    "    for i,s in enumerate(sizes):\n",
    "      for ep in range(10):\n",
    "              image, label = data_generator.generate_batch(\"train\",\n",
    "                                                           s,\n",
    "                                                           32)\n",
    "              splits = tf.split(label,5,axis=-1)\n",
    "              one_hot_targets = [tf.one_hot(split, _nb_classes, axis=-1) for split in splits]\n",
    "              labels_onehot = tf.squeeze(tf.concat(one_hot_targets,axis=-1))\n",
    "              offset_target_var = tf.concat([tf.zeros_like(tf.expand_dims(\n",
    "              labels_onehot[:, 0], 1)), labels_onehot[:, :-1]], axis=1)\n",
    "              ntm_input = tf.concat([image, offset_target_var], axis=2)\n",
    "              output = model(ntm_input)\n",
    "              accuracy = metric_accuracy(s, 10, label, output)\n",
    "              for ixx, inst in enumerate([1,2,5,9]):\n",
    "                  test_error[i][ixx](accuracy[inst])\n",
    "    print('', end='\\t')\n",
    "    for size in test_error:\n",
    "        for ixx in range(4):\n",
    "            print('%.1f' % (size[ixx].result()*100.0), end=' ')\n",
    "        print('\\t')\n",
    "    print('')\n",
    "            \n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Tep7ieufXdzm"
   },
   "outputs": [],
   "source": [
    "def metric_accuracy(_nb_classes,_nb_samples_per_class,labels, outputs):\n",
    "    seq_length = _nb_classes * _nb_samples_per_class\n",
    "    outputs_split = tf.split(outputs,5,axis=-1)\n",
    "    outputs = [tf.argmax(split, axis=-1) for split in outputs_split]\n",
    "    outputs = np.stack(outputs,axis=-1)\n",
    "\n",
    "    correct = [0] * seq_length\n",
    "    total = [0] * seq_length\n",
    "    for i in range(np.shape(labels)[0]):\n",
    "        label = labels[i]\n",
    "        output = outputs[i]\n",
    "        class_count = {}\n",
    "        for j in range(seq_length):\n",
    "            label_str = labelstr(label[j])\n",
    "            output_str = labelstr(output[j])\n",
    "            class_count[label_str] = class_count.get(label_str, 0) + 1\n",
    "            total[class_count[label_str]] += 1\n",
    "            if label_str == output_str:\n",
    "                correct[class_count[label_str]] += 1\n",
    "    return [float(correct[i]) / total[i] if total[i] > 0. else 0.\n",
    "            for i in range(1, _nb_samples_per_class + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "F8xTd-Ayifvw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LSTM', 'DNC', 'LRUold'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "obszQjx6Wtr7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\t5\t\t\t10\t\t\t15\t\t\t20\t\t\t25\t\t\t50\t\t\t100\t\t\t\n",
      "\t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t\t23.2 31.2 37.8 49.3 \t\n",
      "13.9 16.4 19.5 25.1 \t\n",
      "8.0 10.0 12.6 15.9 \t\n",
      "6.5 8.0 9.6 12.1 \t\n",
      "4.7 6.3 7.2 9.6 \t\n",
      "2.1 2.7 3.2 4.1 \t\n",
      "1.0 1.0 1.2 1.6 \t\n",
      "\n",
      "size\t5\t\t\t10\t\t\t15\t\t\t20\t\t\t25\t\t\t50\t\t\t100\t\t\t\n",
      "\t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t\t80.9 88.5 93.1 95.6 \t\n",
      "71.8 79.1 86.9 90.7 \t\n",
      "63.2 71.6 80.0 86.5 \t\n",
      "57.5 66.4 76.8 82.1 \t\n",
      "52.2 61.9 70.5 76.7 \t\n",
      "37.2 43.9 49.2 55.2 \t\n",
      "23.6 26.9 28.5 32.5 \t\n",
      "\n",
      "size\t5\t\t\t10\t\t\t15\t\t\t20\t\t\t25\t\t\t50\t\t\t100\t\t\t\n",
      "\t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t\t77.3 87.4 92.1 95.3 \t\n",
      "69.2 77.8 86.8 90.2 \t\n",
      "63.2 73.1 82.7 87.2 \t\n",
      "57.5 68.1 78.0 83.7 \t\n",
      "51.3 62.0 72.5 81.5 \t\n",
      "35.4 45.3 56.6 63.7 \t\n",
      "19.3 25.3 29.6 28.1 \t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "for name, model in models.items():\n",
    "  err = test(model, data_generator, sizes)\n",
    "  errors[name] = err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4Nxb423ihLA"
   },
   "outputs": [],
   "source": [
    "print('Model',end='\\t')\n",
    "for s in sizes:\n",
    "  print(s,end='\\t')\n",
    "print()\n",
    "for model, error in errors.items():\n",
    "  print(model,end='\\t')\n",
    "  for err in error:\n",
    "    print(float(err.result()),end='\\t')\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\t5\t\t\t10\t\t\t15\t\t\t20\t\t\t25\t\t\t50\t\t\t100\t\t\t\n",
      "\t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t1    2    5    10    \t"
     ]
    }
   ],
   "source": [
    "    print('size', end='\\t')\n",
    "    for size in sizes:\n",
    "        print('%d' % size, end='\\t\\t\\t')\n",
    "    print('')\n",
    "    print('\\t', end='')\n",
    "    for size in sizes:\n",
    "        for instance in [1,2,5,10]:\n",
    "            print(f'{instance}    ', end='')\n",
    "        print(f'', end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "copytask-test-compare.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
